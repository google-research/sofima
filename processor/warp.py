# coding=utf-8
# Copyright 2023 The Google Research Authors.
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
"""Processors for image warping and rendering."""

from concurrent import futures
import dataclasses
import json
from typing import Any, Sequence

from absl import logging
from connectomics.common import bounding_box
from connectomics.common import box_generator
from connectomics.common import file
from connectomics.common import geom_utils
from connectomics.common import utils
from connectomics.volume import mask as mask_lib
from connectomics.volume import metadata
from connectomics.volume import subvolume
from connectomics.volume import subvolume_processor
import edt
import numpy as np
from sofima import map_utils
from sofima import warp


ZYX = tuple[int, int, int]
XYZ = tuple[int, int, int]


class StitchAndRender3dTiles(subvolume_processor.SubvolumeProcessor):
  """Renders a volume by stitching 3d tiles placed on a 2d grid."""

  _tile_meshes = None
  _tile_idx_to_xy = None
  _tile_boxes = {}
  _inverted_meshes = {}

  crop_at_borders = False

  def __init__(
      self,
      *,
      tile_map: Sequence[Sequence[int]],
      tile_mesh_path: str,
      tile_pattern_path: str,
      stride: ZYX,
      offset: XYZ = (0, 0, 0),
      margin: int = 0,
      work_size: XYZ = (128, 128, 128),
      order: int = 1,
      parallelism: int = 16,
      input_volinfo=None,
  ):
    """Constructor.

    Args:
      tile_map: yx-shaped grid of tile IDs
      tile_mesh_path: path to a npz file containing 'key_to_idx' and 'x' arrays,
        as generated by `stitch_elastic.aggregate_arrays` and `mesh.solve_mesh`,
        respectively
      tile_pattern_path: volinfo path for the volumes containing individual
        tiles; must contain '{tile_id}', which will be substituted with values
        from `tile_map`
      stride: ZYX stride of the mesh in pixels
      offset: XYZ global offset to apply to the rendered image
      margin: number of pixels away from the tile boundary to ignore during
        rendering; this can be useful is the tiles are more distorted at their
        boundaries. Do not apply to the outer edges of tiles at the edges of the
        grid.
      work_size: see `warp.ndimage_warp`
      order: see `warp.ndimage_warp`
      parallelism: see `warp.ndimage_warp`
      input_volinfo: not used
    """
    del input_volinfo
    self._tile_map = np.array(tile_map)
    self._tile_mesh_path = tile_mesh_path
    self._tile_pattern_path = tile_pattern_path
    self._stride = stride
    self._offset = offset
    self._margin = margin
    self._order = order
    self._parallelism = parallelism
    self._work_size = work_size

    self._key_to_idx = {}
    for y, row in enumerate(tile_map):
      for x, tile_id in enumerate(row):
        self._key_to_idx[(x, y)] = tile_id

  def _open_tile_volume(self, tile_id: int) -> Any:
    """Returns a ZYX-shaped ndarray-like object representing the tile data."""
    raise NotImplementedError(
        'This function needs to be defined in a subclass.'
    )

  def context(self):
    return (0, 0, 0), (0, 0, 0)

  def _collect_tile_boxes(self, tile_shape_zyx: ZYX):
    tile_meshes = StitchAndRender3dTiles._tile_meshes
    assert tile_meshes is not None
    map_box = bounding_box.BoundingBox(
        start=(0, 0, 0),
        size=tile_meshes.shape[2:][::-1],
    )

    for i in range(tile_meshes.shape[1]):
      tx, ty = StitchAndRender3dTiles._tile_idx_to_xy[i]

      mesh = tile_meshes[:, i, ...]
      tg_box = map_utils.outer_box(mesh, map_box, self._stride)

      # Region that can be rendered with the current tile, in global
      # coordinates.
      out_box = bounding_box.BoundingBox(
          start=(
              tg_box.start[0] * self._stride[2]
              + tx * tile_shape_zyx[-1]
              + self._offset[0],
              tg_box.start[1] * self._stride[1]
              + ty * tile_shape_zyx[-2]
              + self._offset[1],
              tg_box.start[2] * self._stride[0] + self._offset[2],
          ),
          size=(
              tg_box.size[0] * self._stride[2],
              tg_box.size[1] * self._stride[1],
              tg_box.size[2] * self._stride[0],
          ),
      )

      StitchAndRender3dTiles._tile_boxes[i] = out_box, tg_box

  def _get_dts(self, shape: ZYX, tx: int, ty: int) -> np.ndarray:
    # Ignore up to _margin pixels on tile edges, with the exception of the
    # tiles at the outer sides of the tile grid.
    mask = np.zeros(shape[1:], dtype=bool)
    if self._margin > 0:
      x0 = self._margin if tx > 0 else 0
      x1 = -self._margin if tx < self._tile_map.shape[-1] - 1 else -1
      y0 = self._margin if ty > 0 else 0
      y1 = -self._margin if ty < self._tile_map.shape[-2] - 1 else -1
      mask[y0:y1, x0:x1] = 1
    else:
      mask[...] = 1

    # Compute a (2d) distance transform of the mask, for use in blending.
    return edt.edt(mask, black_border=True, parallel=0)

  def _load_tile_images(
      self,
      box: bounding_box.BoundingBox,
      tile_shape_zyx: ZYX,
      volstores: dict[int, Any],
      tpe: futures.Executor,
  ) -> set[futures.Future[tuple[np.ndarray, Any]]]:
    fs = set([])
    tile_meshes = StitchAndRender3dTiles._tile_meshes
    assert tile_meshes is not None
    # Bounding boxes for the tile and its mesh in its own coordinate system
    # (with the tile placed at the origin).
    image_box = bounding_box.BoundingBox(
        start=(0, 0, 0), size=tile_shape_zyx[::-1]
    )
    map_box = bounding_box.BoundingBox(
        start=(0, 0, 0),
        size=tile_meshes.shape[2:][::-1],
    )

    for i, (out_box, tg_box) in StitchAndRender3dTiles._tile_boxes.items():
      sub_box = out_box.intersection(box)
      if sub_box is None:
        continue

      logging.info('Processing source %r (%r)', i, out_box)

      coord_map = tile_meshes[:, i, ...]
      tx, ty = StitchAndRender3dTiles._tile_idx_to_xy[i]

      if i not in StitchAndRender3dTiles._inverted_meshes:
        # Add context to avoid rounding issues in map inversion.
        tg_box = tg_box.adjusted_by(start=(-1, -1, -1), end=(1, 1, 1))
        inverted_map = map_utils.invert_map(
            coord_map, map_box, tg_box, stride=self._stride
        )
        # Extrapolate only. The inverted map should not have any holes that
        # can be filled through interpolation.
        inverted_map = map_utils.fill_missing(
            inverted_map, extrapolate=True, interpolate_first=False
        )
        StitchAndRender3dTiles._inverted_meshes[i] = tg_box, inverted_map
      else:
        tg_box, inverted_map = StitchAndRender3dTiles._inverted_meshes[i]

      # Box which can be passed to ndimage_warp to render the *whole* tile.
      # This is within a coordinate system where the source tile is
      # placed at (0, 0, 0).
      local_out_box = out_box.translate((
          -tx * tile_shape_zyx[-1] - self._offset[0],
          -ty * tile_shape_zyx[-2] - self._offset[1],
          -self._offset[2],
      ))

      # Part of the region we can render with the current tile that is
      # actually needed for the current output.
      local_rel_box = sub_box.translate(-out_box.start)
      local_warp_box = local_rel_box.translate(local_out_box.start)

      # Part of the inverted mesh that is needed to render the current
      # region of interest.
      s = 1.0 / np.array(self._stride)[::-1]
      local_map_box = local_warp_box.scale(s).adjusted_by(
          start=(-2, -2, -2), end=(2, 2, 2)
      )
      local_map_box = local_map_box.intersection(tg_box)
      if local_map_box is None:
        continue

      map_query_box = local_map_box.translate(-tg_box.start)
      assert np.all(map_query_box.start >= 0)
      sub_map = inverted_map[map_query_box.to_slice4d()]

      # Part of the source image needed to render the current region
      # of interest.
      data_box = map_utils.outer_box(sub_map, local_map_box, self._stride, 1)
      data_box = data_box.intersection(image_box)
      if data_box is None:
        continue

      dts_2d = self._get_dts(tile_shape_zyx, tx, ty)
      sub_dts = dts_2d[data_box.to_slice_tuple(0, 2)][None, ...]
      sub_dts = np.repeat(sub_dts, data_box.size[2], axis=0)

      # Schedule data loading.
      context = inverted_map, tg_box, local_warp_box, sub_box, sub_dts, data_box
      def _load(context=context, i=i):
        data_box = context[-1]
        image = volstores[i][data_box.to_slice3d()]
        return image, context

      fs.add(tpe.submit(_load))

    return fs

  def process(
      self, subvol: subvolume.Subvolume
  ) -> subvolume_processor.SubvolumeOrMany:
    box = subvol.bbox
    logging.info('Processing %r', box)

    mesh_init = False

    if StitchAndRender3dTiles._tile_meshes is None:
      data_path = self._tile_mesh_path
      with file.Path(data_path).open('rb') as f:
        data = np.load(f, allow_pickle=True)
        StitchAndRender3dTiles._tile_idx_to_xy = {
            v: k for k, v in data['key_to_idx'].item().items()
        }
        StitchAndRender3dTiles._tile_meshes = data['x']
        assert StitchAndRender3dTiles._tile_meshes.shape[1] == len(
            StitchAndRender3dTiles._tile_idx_to_xy
        )
      mesh_init = True

    volstores = {}
    for i in range(StitchAndRender3dTiles._tile_meshes.shape[1]):
      tile_id = self._key_to_idx[StitchAndRender3dTiles._tile_idx_to_xy[i]]
      volstores[i] = self._open_tile_volume(tile_id)

    # Bounding boxes representing a single tile placed the origin.
    tile_shape_zyx = next(iter(volstores.values())).shape
    if mesh_init:
      self._collect_tile_boxes(tile_shape_zyx)

    # For blending, accumulate (weighted) image data as floats. This will
    # be normalized and cast to the desired output type once the image is
    # rendered.
    img = np.zeros(subvol.data.shape[1:], dtype=np.float32)
    norm = np.zeros(subvol.data.shape[1:], dtype=np.float32)

    with futures.ThreadPoolExecutor(max_workers=2) as tpe:
      fs = self._load_tile_images(box, tile_shape_zyx, volstores, tpe)

      for f in futures.as_completed(fs):
        image, (
            inverted_map,
            tg_box,
            local_warp_box,
            sub_box,
            sub_dts,
            data_box,
        ) = f.result()

        image = warp.ndimage_warp(
            image,
            inverted_map,
            self._stride,
            work_size=self._work_size,
            overlap=(0, 0, 0),
            order=self._order,
            image_box=data_box,
            map_box=tg_box,
            out_box=local_warp_box,
            parallelism=self._parallelism,
        )

        warped_dts = warp.ndimage_warp(
            sub_dts,
            inverted_map,
            self._stride,
            work_size=self._work_size,
            overlap=(0, 0, 0),
            image_box=data_box,
            map_box=tg_box,
            out_box=local_warp_box,
            parallelism=self._parallelism,
        )

        out_rel_box = sub_box.translate(-box.start)

        img[out_rel_box.to_slice3d()] += image * warped_dts
        norm[out_rel_box.to_slice3d()] += warped_dts

    # Compute the (distance-from-tile-center-) weighted average of every
    # voxel. This results in smooth transitions between tiles, even if
    # there are some contrast differences.
    ret = img
    ret[norm > 0] /= norm[norm > 0]
    ret = ret.astype(self.output_type(subvol.data.dtype))

    return self.crop_box_and_data(box, ret[None, ...])


class WarpByMap(subvolume_processor.SubvolumeProcessor):
  """Warps data according to an inverse coordinate map.

  Optionally performs on-the-fly downsampling of the warped data. This
  is useful when the source data is available at a higher resolution
  than that required for all downstream processing steps.

  This processor is run over a template output volume, and loads the
  coordinate maps and the data to warp from other volumes, as configured
  in the constructor.
  """

  crop_at_borders = False
  output_num = subvolume_processor.OutputNums.MULTI
  ignores_input_data = True
  _mask_configs: mask_lib.MaskConfigs | None = None

  @dataclasses.dataclass(eq=True)
  class Config(utils.NPDataClassJsonMixin):
    """Configuration for WarpByMap.

    Attributes:
      stride: pixel distance between nearest neighbors of the coordinate map, in
        pixels of the output volume
      map_volinfo: path to the volinfo of the coordinate map volume
      data_volinfo: path to the volinfo of the source data volume
      map_decorator_specs: decorator specs of the coordinate map volume, as a
        JSON string or Python object
      data_decorator_specs: decorator specs of the source data volume, as a JSON
        string or Python object
      map_scale: multiplicative factor for the coordinate map values
      interpolation: interpolation scheme to use (see warp.warp_subvolume)
      downsample: downsampling factor to apply to the data after warping;
        downsampling is performed in XY via area-averaging
      offset: (deprecated, do not use)
      mask_config: MaskConfigs proto in text format; pixels corresponding to the
        positive entries of the mask will be zeroed out, and warping of
        completely masked subvolumes will be skipped
      source_cache_bytes: max. number of bytes to use for the raw data chunk
        cache; it is recommended for the buffer to be large enough to hold a
        single layer of chunks covering the complete subvolume laterally
    """

    # TODO(blakely): Convert stride to Sequence[float]
    stride: float
    map_volinfo: str
    data_volinfo: str
    map_decorator_specs: str | dict[str, Any] | None = None
    data_decorator_specs: str | dict[str, Any] | None = None
    map_scale: float = 1.0
    interpolation: str | None = None
    downsample: int = 1
    offset: float = 0.0
    mask_configs: str | mask_lib.MaskConfigs | None = None
    source_cache_bytes: int = int(1e9)

  def __init__(
      self,
      config: Config,
      input_volinfo=None,
  ):
    """Constructor.

    Args:
      config: Configuration for this processor.
      input_volinfo: VolumeInfo proto of the input.
    """
    self._map_volinfo = config.map_volinfo
    self._scale = config.map_scale
    self._interpolation = config.interpolation
    self._data_volinfo = config.data_volinfo

    # TODO(blakely): Convert these to dataclasses.
    def _get_specs(specs):
      if specs is None:
        return []
      elif isinstance(specs, str):
        return json.loads(specs)
      else:
        return specs

    self._data_decorator_specs = _get_specs(config.data_decorator_specs)
    self._map_decorator_specs = _get_specs(config.map_decorator_specs)

    self._downsample = np.array(
        [config.downsample, config.downsample, 1]
    )  # xyz
    self._target_stride = config.stride
    self._source_stride = config.stride * config.downsample
    self._offset = config.offset
    self._source_cache_bytes = config.source_cache_bytes

    self._mask_config = None
    if config.mask_configs is not None:
      mask_configs = config.mask_configs
      if isinstance(mask_configs, str):
        mask_configs = self._get_mask_configs(config.mask_configs)
      self._mask_configs = mask_configs

  def _load_and_warp(
      self,
      data_box: bounding_box.BoundingBox,
      data_vol,
      map_data: np.ndarray,
      map_box: bounding_box.BoundingBox,
      out_box: bounding_box.BoundingBox,
  ) -> np.ndarray | None:
    """Produces warped data for 'out_box'."""
    data = data_vol[data_box.to_slice4d()]
    if self._mask_configs is not None:
      mask = self._build_mask(self._mask_configs, data_box)
      for c in range(data.shape[0]):
        data[c, ...][mask] = 0
    else:
      mask = None

    if mask is not None and np.all(mask):
      return

    return warp.warp_subvolume(
        data,
        data_box,
        map_data,
        map_box,
        self._source_stride,
        out_box,
        self._interpolation,
        self._offset,
    )

  def _get_map_for_box(
      self, box: bounding_box.BoundingBox
  ) -> tuple[bounding_box.BoundingBox | None, np.ndarray | None]:
    """Loads coordinate map corresponding to the output subvolume."""
    s = 1.0 / self._target_stride
    map_box = box.scale([s, s, 1.0]).adjusted_by(
        start=(-2, -2, 0), end=(2, 2, 0)
    )
    map_vol = self._map_volinfo
    if self._map_decorator_specs:
      map_vol = metadata.DecoratedVolume(
          path=self._map_volinfo,
          decorator_specs=self._map_decorator_specs,
      )
    map_vol = self._open_volume(map_vol)
    map_box = map_vol.clip_box_to_volume(map_box)
    if map_box is None or np.any(map_box.size == 0):
      logging.debug('Clipped map box is None for box %r', box)
      return None, None
    rel_map = map_vol[map_box.to_slice4d()].astype(np.float64) * self._scale

    if np.all(np.isnan(rel_map)):
      logging.debug('Map is invalid for %r.', map_box)
      return None, None

    return map_box, rel_map

  def _generate_boxes_to_warp(self, data_vol, box: bounding_box.BoundingBox):
    """Generates work items for which to perform warping."""
    map_box, rel_map = self._get_map_for_box(box)
    if map_box is None or np.any(map_box.size == 0):
      logging.debug('No map found for %r.', box)
      return

    data_box = map_utils.outer_box(rel_map, map_box, self._source_stride, 1)
    data_box = data_vol.clip_box_to_volume(data_box)
    if data_box is None or np.any(data_box.size == 0):
      logging.debug('Data out of bounds for map: %r.', map_box)
      return

    # 32k is the max input size supported by OpenCV's remap() function
    # used in warp.warp_subvolume. If the input is smaller, we can generate
    # output for 'box' directly.
    if np.all(data_box.size < 2**15):
      yield box, data_box, rel_map, map_box
      return

    # Bail out if the output box is small, yet the input data remains large.
    if np.any(box.size[:2] < self._target_stride * 3):
      logging.debug('Output box too small: %r', box)
      # TODO(blakely): Re-enable counters
      # beam.metrics.Metrics.counter('warp-by-map', 'map-failures').inc()
      return

    # Otherwise, divide the current output box into a 2x2 grid of smaller
    # boxes, and try again.
    subvol_size = np.array(list(-(-box.size[:2] // 2)) + [box.size[2]])
    subvol_size = -(-subvol_size // self._downsample) * self._downsample

    calc = box_generator.BoxGenerator(box, subvol_size, box_overlap=(0, 0, 0))
    for sub_box in calc.boxes:
      yield from self._generate_boxes_to_warp(data_vol, sub_box)

  def process(self, subvol: subvolume.Subvolume) -> subvolume.SubvolumeOrMany:
    box = subvol.bbox
    input_ndarray = subvol.data

    data_vol = self._data_volinfo
    if self._data_decorator_specs:
      data_vol = metadata.DecoratedVolume(
          path=self._data_volinfo,
          decorator_specs=self._data_decorator_specs,
      )
    data_vol = self._open_volume(data_vol)

    # TODO(blakely): Re-enable this cache size check.
    # min_cache_size = (
    #     -(-box.size[0] // data_vol.info.chunksize.x)
    #     * data_vol.info.chunksize.x
    #     * -(-box.size[1] // data_vol.info.chunksize.y)
    #     * data_vol.info.chunksize.y
    #     * data_vol.info.chunksize.z
    #     * ndarray.data_type_to_size[data_vol.info.channel_type]
    # )
    # if min_cache_size > self._source_cache_bytes:
    #   logging.warning(
    #       (
    #           'Cache size needs to be at least %d bytes in order '
    #           'to optimally utilize data loaded from the source volume.'
    #       ),
    #       min_cache_size,
    #   )

    warped = np.zeros(
        [input_ndarray.shape[0]] + box.size[::-1].tolist(),
        dtype=input_ndarray.dtype,
    )
    del input_ndarray

    # Warp data section-wise.
    for z in range(warped.shape[1]):
      curr_box = bounding_box.BoundingBox(
          start=box.start + [0, 0, z], size=[box.size[0], box.size[1], 1]
      )
      logging.debug('warping z=%d', z)

      for out_box, data_box, map_data, map_box in self._generate_boxes_to_warp(
          data_vol, curr_box
      ):
        logging.debug('warp %r -> %r via map %r', data_box, out_box, map_box)
        warp_box = out_box.scale(self._downsample)
        warped_sec = self._load_and_warp(
            data_box, data_vol, map_data, map_box, warp_box
        )
        if warped_sec is None:
          continue
        if warp_box != out_box:
          downsampled = []

          # Cast to a wider type to eliminate overflow or reduce precision
          # loss in integral image computation.
          if warped_sec.dtype in (np.uint8, np.uint32):
            warped_sec = warped_sec.astype(np.int64)
          elif warped_sec.dtype == np.float32:
            warped_sec = warped_sec.astype(np.float64)
            warped_sec = np.nan_to_num(warped_sec)
          else:
            raise NotImplementedError(
                f'Downsampling of {warped_sec.dtype} not supported.'
            )

          for chan in range(warped_sec.shape[0]):
            svt = geom_utils.integral_image(warped_sec[chan, ...])
            down_box, down_data = geom_utils.downsample_area(
                svt, warp_box, self._downsample, warped.dtype
            )
            downsampled.append(down_data)
          write_box = down_box.translate(-box.start)
          warped[write_box.to_slice4d()] = np.concatenate(
              downsampled, axis=0
          ).astype(warped.dtype)
        else:
          write_box = out_box.translate(-box.start)
          warped[write_box.to_slice4d()] = warped_sec

    return [self.crop_box_and_data(box, warped)]
